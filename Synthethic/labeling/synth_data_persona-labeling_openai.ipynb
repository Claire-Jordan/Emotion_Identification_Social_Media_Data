{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d01b25d-9a94-4a6a-8e68-a0d28a53a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b49a5b1d-e898-4dc4-98ac-98b4e094d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enisear = pd.read_csv('../../enISEAR.tsv', delimiter= '\\t')\n",
    "emotions = list(enisear['Prior_Emotion'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77cc645f-6766-43c0-bb92-5c9c9538934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "API_TOKEN = ''\n",
    "\n",
    "login(token = API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32904e35-0e90-4324-9f9b-e4629fd0ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(text):\n",
    "\n",
    "    \"\"\"Create prompt used for all LLMs\n",
    "\n",
    "    Args: \n",
    "        text to label\n",
    "    \n",
    "\n",
    "    Retruns:\n",
    "        complete prompt per text for the LLM with randomly selected example - 1-shot\n",
    "    \n",
    "    \"\"\"    \n",
    "\n",
    "    label_prompt = f\"\"\" Given a piece of text, you have to label to which of the following emotions\n",
    "    it corresponds. The options are: Anger, Fear, Guilt, Shame, Joy, Sadness, Disgust. Do not choose any other emotion. \n",
    "    Please return only one of the previous options as a single word. Do not provide an explanation. \"\"\"\n",
    "\n",
    "\n",
    "    task = f\"\"\"What is the label of this text: {text} \"\"\"\n",
    "\n",
    "    example_row = enisear.sample(1).iloc[0]\n",
    "    example = f\"text: {example_row['text']}, emotion: {example_row['sentiment']}\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": label_prompt},\n",
    "        {\"role\": \"user\", \"content\": example},\n",
    "        {\"role\": \"user\", \"content\": task}\n",
    "    ]\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7090a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403eae07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cabe2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "configs =  [    {\n",
    "        \"data_to_label\": \"../full_emotions/gpt4o_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/gpt4o_full_emotions.csv\",\n",
    "    },\n",
    "\n",
    "    {\n",
    "         \"data_to_label\": \"../full_emotions/gpt4o_mini_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/gpt4o_mini_full_emotions.csv\",\n",
    "    },   \n",
    "    {\n",
    "        \"data_to_label\": \"../full_emotions/llama31_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/llama31_full_emotions.csv\",\n",
    "    },\n",
    "     {\n",
    "        \"data_to_label\": \"../full_emotions/llama33_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/llama33_full_emotions.csv\",\n",
    "    },   \n",
    "    {\n",
    "        \"data_to_label\": \"../full_emotions/qwen3_30BA3B_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/qwen3_30BA3B_full_emotions.csv\",\n",
    "    },\n",
    "    {\n",
    "        \"data_to_label\": \"../full_emotions/llama33_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/llama33_full_emotions.csv\",\n",
    "    },\n",
    "     {\n",
    "        \"data_to_label\": \"../full_emotions/enisear_preprocessed.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/enisear_preprocessed.csv\",\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "configs =  [   \n",
    "    {\n",
    "        \"data_to_label\": \"../full_emotions/server_data/qwen3_32B_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/qwen3_32B_full_emotions.csv\",\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2084800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_gpt(df, model):\n",
    "\n",
    "    \"\"\"Run GPT API on dataframe\n",
    "\n",
    "    Returns:\n",
    "        dataframe: dataframe containing GPT's answers for every text\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "    output_list = []\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), desc=\"Processing labeling\", total=df.shape[0]):  \n",
    "        preds = []\n",
    "        for n in range(0, 3):\n",
    "            response = client.responses.create(\n",
    "                model=model,\n",
    "                input=create_prompt(row['Sentence'])\n",
    "            )\n",
    "\n",
    "\n",
    "            preds.append(response.output_text)\n",
    "\n",
    "        row_dict = row.to_dict()\n",
    "        row_dict.update({\n",
    "            'pred_1': preds[0],\n",
    "            'pred_2': preds[1],\n",
    "            'pred_3': preds[2]\n",
    "        })\n",
    "\n",
    "        output_list.append(row_dict)\n",
    "    result = pd.DataFrame(output_list)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39061f51-649a-4bae-ba83-3c32b28e7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def majority_calculation(df, model, label_cols=emotions):\n",
    "    \"\"\"from all 3 runs, get the majority answer. Choose one at random if equal\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): dataframe containing 3 predictions per model\n",
    "        model (str): name of the model for which we get majority vote\n",
    "        label_cols (list, optional): emotion columns. Defaults to emotions.\n",
    "    \"\"\"\n",
    "    def find_max(row):\n",
    "        max_count = row[label_cols].value_counts().max()  # Get max count\n",
    "        max_labels = row[label_cols].value_counts()[row[label_cols].value_counts() == max_count].index.tolist()\n",
    "        return random.choice(max_labels) if len(max_labels) > 1 else max_labels[0]  # Choose randomly if tie\n",
    "    \n",
    "    df[f'{model}_label'] = df.apply(find_max, axis=1)  # Apply to each row\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72360b3f-d73c-43eb-8846-b1c46f13eb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing labeling: 100%|██████████| 1001/1001 [33:44<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for config in configs:\n",
    "    data_to_label = config[\"data_to_label\"]\n",
    "    saving_file_path = config[\"saving_file_path\"]\n",
    "\n",
    "    synth = pd.read_csv(data_to_label, index_col = 0)\n",
    "    synth = synth.loc[:, ~synth.columns.str.startswith('Unnamed')]\n",
    "\n",
    "    \n",
    "    gpt = run_gpt(synth, 'gpt-4o-mini')\n",
    "    \n",
    "    gpt = majority_calculation(gpt, 'gpt_4o_mini',['pred_1', 'pred_2', 'pred_3'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    gpt.to_csv(saving_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73be1af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_paths = {'gpt4o':\n",
    "    {\n",
    "        \"data_to_label\": \"../synth_data_openai/gpt4o_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/gpt4o_full_emotions.csv\",\n",
    "    },\n",
    "              'gpt40_mini':\n",
    "    {\n",
    "         \"data_to_label\": \"../synth_data_openai/gpt4o_mini_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/gpt4o_mini_full_emotions.csv\",\n",
    "    },  \n",
    "              'llama31':\n",
    "    {\n",
    "        \"data_to_label\": \"llama31_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/llama31_full_emotions.csv\",\n",
    "    },\n",
    "              'llama33':\n",
    "     {\n",
    "        \"data_to_label\": \"llama33_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/llama33_full_emotions.csv\",\n",
    "    },   \n",
    "              'qwen30B_A3B':\n",
    "    {\n",
    "        \"data_to_label\": \"qwen3_30BA3B_full_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/qwen3_30BA3B_full_emotions.csv\",\n",
    "    },\n",
    "              'qwen32B':\n",
    "     {\n",
    "        \"data_to_label\": \"synth_data_qwen/qwen3_32B_all_emotions.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/qwen3_32B_full_emotions.csv\",\n",
    "    },\n",
    "              'enisear':\n",
    "     {\n",
    "        \"data_to_label\": \"enisear_preprocessed.csv\",\n",
    "        \"saving_file_path\": \"../full_emotions/enisear_preprocessed.csv\",\n",
    "    }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb33c4c2-8490-4046-bf6e-a760aaf54990",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "for data, dict in data_paths.items():\n",
    "    \n",
    "    datasets[data] = pd.read_csv(dict['saving_file_path'], index_col=0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b09065",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, df in datasets.items():\n",
    "    value_cts = df['gpt_4o_label'].value_counts()\n",
    "    print(f'dataset: {data}, \\n value_cts {value_cts}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
